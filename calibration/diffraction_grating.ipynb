{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shshin/.conda/envs/hyper3d/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "import sys, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/home/shshin/Scalable-Hyperspectral-3D-Imaging')\n",
    "from hyper_sl.utils import _constants as C\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid pattern 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Define the size of the image\n",
    "width = 1280\n",
    "height = 720\n",
    "\n",
    "# Define the size of each dot\n",
    "dot_size = 3\n",
    "margin = 200\n",
    "\n",
    "# Create a new image with a white background\n",
    "img = Image.new('RGB', (width, height), color='black')\n",
    "\n",
    "# Get a drawing context for the image\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# Draw dots on the image in a grid pattern\n",
    "for x in range(0, width, dot_size + margin):\n",
    "    for y in range(0, height, dot_size + margin):\n",
    "        draw.ellipse((x, y, x+dot_size, y+dot_size), fill='white')\n",
    "        \n",
    "# Save the image\n",
    "img.save('grid_dot_pattern.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input pixel location where white dots exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set illum dimensions and dot spacing\n",
    "illum_height = 720\n",
    "illum_width = 1280\n",
    "dot_size = 5\n",
    "\n",
    "# create tensor representing black illum\n",
    "illum = torch.zeros((illum_height, illum_width))\n",
    "\n",
    "\n",
    "# get user input for circle center locations\n",
    "centers = []\n",
    "while True:\n",
    "    center_input = input(\"Enter the x,y coordinates of a circle center (or 'done' to finish): \")\n",
    "    if center_input == 'done':\n",
    "        break\n",
    "    else:\n",
    "        x, y = center_input.split(',')\n",
    "        centers.append((int(x), int(y)))\n",
    "\n",
    "# loop through the illum and set pixels within the circles to white\n",
    "for i in range(illum_height):\n",
    "    for j in range(illum_width):\n",
    "        for center in centers:\n",
    "            if (i - center[0])**2 + (j - center[1])**2 <= dot_size**2:\n",
    "                illum[i, j] = 1\n",
    "\n",
    "# resize the illum to a square and convert to a PyTorch variable\n",
    "illum = illum.unsqueeze(0).unsqueeze(0)\n",
    "illum = F.interpolate(illum, size=(illum_height, illum_width))\n",
    "illum = illum.squeeze()\n",
    "illum_np = illum.squeeze().numpy()\n",
    "\n",
    "# plot the illum using matplotlib\n",
    "plt.imshow(1-illum, cmap='binary')\n",
    "cv2.imwrite('dot.png',illum_np*255.)\n",
    "# plt.imshow(illum), plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set illum dimensions and dot spacing\n",
    "illum_height = 720\n",
    "illum_width = 1280\n",
    "\n",
    "# create tensor representing black illum\n",
    "illum = torch.zeros((illum_height, illum_width))\n",
    "\n",
    "\n",
    "# get user input for circle center locations\n",
    "illum[int(illum_height/2)-1:int(illum_height/2)+1,int(illum_width/2)-1:int(illum_width/2)+1]=1\n",
    "illum_np = illum.numpy()\n",
    "cv2.imwrite('dot.png',illum_np*255.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera captured Image 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bring_cap_img():\n",
    "    img_path = ''\n",
    "    img_fn = ''\n",
    "    captured_img = cv2.imread(os.path.join(img_path, img_fn), -1)\n",
    "    captured_img = torch.tensor(captured_img)\n",
    "    \n",
    "    return captured_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_idx_real():\n",
    "    capt_img = bring_cap_img()\n",
    "    idx = torch.where(capt_img == 1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth 알아내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic of projector\n",
    "\n",
    "proj_sensor_diag = C.PROJ_DIAG *1e-3\n",
    "proj_focal_length = C.PROJ_FOCAL_LENGTH *1e-3\n",
    "proj_H = 720\n",
    "proj_W = 1280\n",
    "sensor_width_proj = torch.sin(torch.atan2(torch.tensor(proj_H),torch.tensor(proj_H)))*proj_sensor_diag\n",
    "proj_pitch = sensor_width_proj/proj_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intrinsic of camera\n",
    "\n",
    "cam_H, cam_W = 1536, 2048\n",
    "sensor_width_cam = 5.32 * 1e-3\n",
    "cam_pitch = sensor_width_cam / cam_H\n",
    "focal_length_cam = 8 * 1e-3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unprojection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unprojection(depth):\n",
    "        \"\"\" Unproject camera sensor coord plane to world coord\n",
    "\n",
    "            input : depth\n",
    "            return : world coordinate X,Y,Z\n",
    "            \n",
    "        \"\"\"\n",
    "        c, r = torch.meshgrid(torch.linspace(0,cam_H-1,cam_H), torch.linspace(0,cam_W-1,cam_W), indexing='ij') # 행렬 indexing\n",
    "        \n",
    "        x_c, y_c = (r-cam_W/2)*cam_pitch, (c-cam_H/2)*cam_pitch\n",
    "        x_c, y_c = x_c.reshape(cam_W*cam_H), y_c.reshape(cam_W*cam_H)\n",
    "        # z_c = torch.zeros_like(x_c)\n",
    "        # z_c[:] = -focal_length_cam\n",
    "        \n",
    "        X,Y,Z = -x_c/focal_length_cam*depth, -y_c/focal_length_cam*depth, -depth\n",
    "        \n",
    "        return X,Y,Z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extrinsic matrix of projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrinsic_proj_real():\n",
    "        \"\"\" World coordinate to real proj's coordinate\n",
    "        \n",
    "        \"\"\"\n",
    "        extrinsic_proj_real = torch.zeros((4,4)).to(device)\n",
    "        # no rotation\n",
    "        extrinsic_proj_real[0,0] = 1 \n",
    "        extrinsic_proj_real[1,1] = 1\n",
    "        extrinsic_proj_real[2,2] = 1\n",
    "\n",
    "        # translate + x 50e-3\n",
    "        extrinsic_proj_real[0,3] = 50e-3 \n",
    "        extrinsic_proj_real[3,3] = 1\n",
    "        \n",
    "        return extrinsic_proj_real"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(X,Y,Z):\n",
    "        \"\"\"\n",
    "            input : object's XYZ coordinate\n",
    "                    extrinsic matrix of rproj to vproj (vproj)\n",
    "                    focal length of virtual projector\n",
    "                    \n",
    "            outputs : virtual projector sensor coordinate (in virtual proj's coordinate)\n",
    "        \"\"\"\n",
    "\n",
    "        # focal_length_proj_virtual : 3, 77\n",
    "\n",
    "        X,Y,Z = X.flatten(), Y.flatten(), Z.flatten()\n",
    "        XYZ1 = torch.stack((X,Y,Z,torch.ones_like(X)), dim = 0).to(device=device)\n",
    "\n",
    "        # XYZ coords in virtual proj's coordinate                   \n",
    "        XYZ_vir = torch.linalg.inv(extrinsic_proj_real())@XYZ1\n",
    "        XYZ_vir = XYZ_vir[:3,:] \n",
    "        \n",
    "        print(XYZ_vir.shape)\n",
    "        XYZ_vir_z = torch.unsqueeze(XYZ_vir[2,:] , dim = 0)\n",
    "\n",
    "        xy_proj = (-proj_focal_length*XYZ_vir[:2,:]/XYZ_vir_z)\n",
    "\n",
    "        return xy_proj "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### find the idx of white camera pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_idx(xy_proj, illum):\n",
    "    \n",
    "    r_proj = xy_proj[0,:]/proj_pitch + proj_W/2\n",
    "    c_proj = xy_proj[1,:]/proj_pitch + proj_H/2\n",
    "\n",
    "    rc_proj = torch.cat((r_proj.unsqueeze(dim = 1), c_proj.unsqueeze(dim =1)), dim = 1)\n",
    "\n",
    "    r_proj, c_proj = rc_proj[...,1], rc_proj[...,0]\n",
    "    \n",
    "    cond = (0<= r_proj)*(r_proj < proj_H)*(0<=c_proj)*(c_proj< proj_W)\n",
    "    r_proj_valid, c_proj_valid = r_proj[cond], c_proj[cond]\n",
    "    r_proj_valid, c_proj_valid = torch.tensor(r_proj_valid), torch.tensor(c_proj_valid)  # TODO: do we need this?\n",
    "\n",
    "    new_idx = proj_W * r_proj_valid.long() + c_proj_valid.long()      \n",
    "    \n",
    "    illum_img = torch.zeros(size=(640,640))\n",
    "\n",
    "    illum = illum.reshape(proj_H*proj_W).to(device=device)\n",
    "    valid_pattern_img=illum[new_idx]\n",
    "\n",
    "    illum_img = torch.zeros(size=(cam_H*cam_W,), device = device)\n",
    "    illum_img[cond.flatten()] = valid_pattern_img\n",
    "    \n",
    "    illum_img = illum_img.reshape(cam_H, cam_W)\n",
    "    \n",
    "    check = torch.where(illum_img == 1)\n",
    "    \n",
    "    return check, illum_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth value to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized depth value :  tensor([-1.4431], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# optimize depth value\n",
    "\n",
    "epoch = 1000\n",
    "loss_f = torch.nn.L1Loss()\n",
    "\n",
    "lr = 1e-3\n",
    "decay_step = 500\n",
    "\n",
    "losses = []\n",
    "\n",
    "depth_value = torch.randn(1, requires_grad = True, device = device)\n",
    "print('initialized depth value : ', depth_value)\n",
    "\n",
    "optimizer = torch.optim.Adam([depth_value], lr = lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=decay_step, gamma = 0.5)\n",
    "\n",
    "for i in range(epoch):\n",
    "    # depth value\n",
    "    depth = torch.zeros(size=(cam_H* cam_W,))\n",
    "    depth[:] = depth_value\n",
    "\n",
    "    # Unproject to 3D points\n",
    "    X,Y,Z = unprojection(depth=depth)\n",
    "\n",
    "    # Projector to projector\n",
    "    xy_proj = projection(X,Y,Z)\n",
    "\n",
    "    # find camera index\n",
    "    cam_idx, illum_img = find_idx(xy_proj, illum)\n",
    "\n",
    "    # index of real captured img\n",
    "    real_idx = find_idx_real()\n",
    "\n",
    "    loss = loss_f(cam_idx,real_idx)\n",
    "    \n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "            print(f\" Epoch : {epoch}, Loss: {loss.item()}, LR: {optimizer.param_groups[0]['lr']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffraction grating calibration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### camera pixel position from catured image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 파장의 빛이 있는 camera pixel 위치 알아내기?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### camera pixel position from unproj & proj method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyper3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fa623eb3390c47c076f568bf88f24d6007a788d3fe47958c8bfce56c724a2ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
